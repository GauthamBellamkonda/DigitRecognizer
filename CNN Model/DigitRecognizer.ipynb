{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GauthamBellamkonda/DigitRecognizer/blob/main/CNN%20Model/src/DigitRecognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aTEJe4-IOu-M"
   },
   "outputs": [],
   "source": [
    "# Use this on Google Colab\n",
    "# !pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qco4qY7imsFc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 10:03:01.491630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-25 10:03:01.491651: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Use this on Google Colab\n",
    "# %tensorflow_version 2.x \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UpAZCP1u3Q9c"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels\n",
    "test_labels = test_labels\n",
    "\n",
    "train_images = train_images.reshape(-1, 28 , 28, 1) / 255.0\n",
    "test_images = test_images.reshape(-1, 28 , 28, 1) / 255.0\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ePLcCVMqoZ4t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,586\n",
      "Trainable params: 184,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 10:53:38.932669: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1383 - accuracy: 0.9592 - val_loss: 0.0389 - val_accuracy: 0.9872 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.00095.\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.0352 - val_accuracy: 0.9884 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0009025.\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0252 - val_accuracy: 0.9920 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.000857375.\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0292 - val_accuracy: 0.9908 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0008145062499999999.\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0251 - val_accuracy: 0.9915 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0007737809374999998.\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0286 - val_accuracy: 0.9916 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0007350918906249999.\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0267 - val_accuracy: 0.9911 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0006983372960937497.\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0271 - val_accuracy: 0.9924 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0006634204312890623.\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0237 - val_accuracy: 0.9926 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0006302494097246091.\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0354 - val_accuracy: 0.9913 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0005987369392383787.\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0262 - val_accuracy: 0.9928 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0005688000922764596.\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0358 - val_accuracy: 0.9904 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0005403600876626366.\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0291 - val_accuracy: 0.9915 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005133420832795048.\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0287 - val_accuracy: 0.9927 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.00048767497911552955.\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0307 - val_accuracy: 0.9928 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.000463291230159753.\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 9.8405e-04 - accuracy: 0.9997 - val_loss: 0.0261 - val_accuracy: 0.9931 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00044012666865176535.\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 1.2490e-04 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9941 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004181203352191771.\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 2.3425e-05 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9941 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0003972143184582182.\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.4290e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9943 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.00037735360253530727.\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 8.3892e-06 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9943 - lr: 3.7735e-04\n",
      "Accuracy:  99.43000078201294 %\n"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=1)\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=5,activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(64,kernel_size=5,activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "epochs=20\n",
    "model.summary()\n",
    "history = model.fit(train_images,train_labels, batch_size=60, epochs = epochs, \n",
    "                    validation_data = (test_images, test_labels), callbacks=[annealer, tensorboard_callback], verbose=1)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", 100*max(history.history['val_accuracy']), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eUUlZxsuOK1C"
   },
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, \"./model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DigitRecognizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
